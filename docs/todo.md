ã„ã„æµã‚Œï¼**ï¼ˆç§è¦‹ï¼‰**
ç¾æ™‚ç‚¹ã®é€²æ—ã¨æ®‹ã‚¿ã‚¹ã‚¯ã‚’æœ€æ–°åŒ–ã—ã¾ã—ãŸã€‚ä¸Šã‹ã‚‰æ½°ã›ã°MVPãŒé–‰ã˜ã¾ã™ã€‚

---

# é€²æ—ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆæœ€æ–°ï¼‰

## âœ… å®Œäº†

* [x] ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé››å½¢ï¼ˆNode 18+/ESM, pnpm, tsupï¼‰
* [x] Lintï¼ˆESLint v9 ãƒ•ãƒ©ãƒƒãƒˆæ§‹æˆï¼‰/ Prettier
* [x] Typecheckï¼ˆ`tsconfig.typecheck.json` / `pnpm typecheck`ï¼‰
* [x] ãƒ†ã‚¹ãƒˆåŸºç›¤ï¼ˆVitestã€`pretest -> build`ï¼‰
* [x] Codexã‚¹ã‚¿ãƒ–ï¼ˆ`tests/fixtures/codex-stub.js`ï¼‰
* [x] **plan ã‚³ãƒãƒ³ãƒ‰**

  * [x] `--output-schema`/`--json` æ¤œå‡ºï¼ˆhelpå¼·åŒ–ï¼‰
  * [x] `--force-schema`
  * [x] Ajv **2020-12** æ¤œè¨¼ï¼ˆ`ajv/dist/2020.js`ï¼‰
  * [x] ç”Ÿæˆç‰©ä¿å­˜ï¼ˆ`.codex-parallel/plan-*.json`, `plan.prompt-*.txt`ï¼‰
  * [x] ãƒ†ã‚¹ãƒˆï¼šã‚¹ã‚¿ãƒ–ã§Plan JSONã‚’å–å¾—
* [x] **assign ã‚³ãƒãƒ³ãƒ‰ï¼ˆæœ€å°ï¼‰**

  * [x] `--plan` èª­ã¿è¾¼ã¿ã€`--map` ã§ worktree ã«å‰²å½“
  * [x] `--codex-home-template` å±•é–‹
  * [x] å‡ºåŠ›ï¼š`.codex-parallel/assignments-*.json`
  * [x] ãƒ†ã‚¹ãƒˆï¼šå‰²å½“/ä¿å­˜ã‚’æ¤œè¨¼
* [x] **schedulerï¼ˆbuildBatchesï¼‰**

  * [x] ä¾å­˜DAGâ†’ä¸¦åˆ—ãƒãƒƒãƒåŒ–
  * [x] å¾ªç’°æ¤œå‡º
  * [x] ãƒ†ã‚¹ãƒˆï¼šãƒˆãƒãƒ­ã‚¸ãƒ¼/å¾ªç’°

---

## ğŸ”œ æ®‹ã‚¿ã‚¹ã‚¯ï¼ˆMVPå¿…é ˆï¼‰

### A. `run` ã‚³ãƒãƒ³ãƒ‰ï¼ˆã‚³ã‚¢ï¼‰
äº†è§£ï¼ã“ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‹ã‚‰**TODOã«æ²¿ã£ã¦å®Ÿè£…**ã‚’é€²ã‚ã¾ã—ãŸã€‚ã¾ãšã¯ **A: runã‚³ãƒãƒ³ãƒ‰ï¼ˆã‚³ã‚¢ï¼‰** ã‚’æœ€å°æ§‹æˆã€œå¿…è¦ååˆ†ã¾ã§ä¸€æ°—ã«å…¥ã‚Œã¦ã€ãƒ†ã‚¹ãƒˆã‚‚è¿½åŠ ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ /æ›´æ–°ã—ã¦ãã ã•ã„ï¼ˆå…¨ç½®æ›OKï¼‰ã€‚å…¥ã‚ŒãŸã‚‰ `pnpm build && pnpm test` ã§é€šã‚‹æƒ³å®šã§ã™ï¼ˆç§è¦‹ï¼‰ã€‚

---

```diff
=== BEGIN FILE: src/core/runner.ts ===
+import fs from "node:fs";
+import path from "node:path";
+import os from "node:os";
+import { spawn } from "node:child_process";
+import readline from "node:readline";
+import crypto from "node:crypto";
+import { buildBatches } from "./scheduler.js";
+import type { Assignment, Plan, TaskSpec } from "./types";
+
+// ---------- CODEX_HOME ç«¶åˆæ¤œçŸ¥ ----------
+export class DuplicateCodexHomeError extends Error {
+  homes: string[];
+  constructor(message: string, homes: string[]) {
+    super(message);
+    this.name = "DuplicateCodexHomeError";
+    this.homes = homes;
+  }
+}
+
+export function ensureUniqueCodexHomes(
+  assignments: Assignment[],
+  { autoIsolate }: { autoIsolate: boolean }
+): { assignments: Assignment[]; mapping: Record<string, string> } {
+  const byHome = new Map<string, number[]>();
+  assignments.forEach((a, i) => {
+    const arr = byHome.get(a.codexHome) ?? [];
+    arr.push(i);
+    byHome.set(a.codexHome, arr);
+  });
+
+  const dups = [...byHome.entries()].filter(([, idxs]) => idxs.length > 1);
+  if (dups.length === 0) {
+    return {
+      assignments: assignments.map((a) => ({ ...a })),
+      mapping: Object.fromEntries(assignments.map((a) => [a.taskId, a.codexHome])),
+    };
+  }
+  if (!autoIsolate) {
+    const homes = dups.map(([h]) => h);
+    throw new DuplicateCodexHomeError(
+      `Duplicate CODEX_HOME detected: ${homes.join(
+        ", "
+      )}. Use --auto-isolate to suffix unique directories.`,
+      homes
+    );
+  }
+  const cloned = assignments.map((a) => ({ ...a }));
+  for (const [, idxs] of dups) {
+    for (let j = 1; j < idxs.length; j++) {
+      const i = idxs[j];
+      const short = crypto.randomUUID().slice(0, 6);
+      cloned[i].codexHome = `${cloned[i].codexHome}-iso-${short}`;
+    }
+  }
+  return {
+    assignments: cloned,
+    mapping: Object.fromEntries(cloned.map((a) => [a.taskId, a.codexHome])),
+  };
+}
+
+// ---------- events.ndjson ãƒ©ã‚¤ã‚¿ãƒ¼ ----------
+type EventRecord = {
+  t: number;
+  type: "state" | "stdout" | "stderr" | "jsonl";
+  runId: string;
+  data: any;
+};
+
+function createEventsWriter(filepath: string) {
+  fs.mkdirSync(path.dirname(filepath), { recursive: true });
+  const ws = fs.createWriteStream(filepath, { flags: "a" });
+  let queued = 0;
+  return {
+    write(obj: EventRecord) {
+      // è¡Œãƒãƒƒãƒ•ã‚¡è©°ã¾ã‚Šå¯¾ç­–ã§è»½ãcork/uncork
+      if (++queued % 200 === 0) ws.cork();
+      ws.write(JSON.stringify(obj) + "\n");
+      if (queued % 200 === 0) process.nextTick(() => ws.uncork());
+    },
+    async close() {
+      await new Promise<void>((r) => ws.end(r));
+    },
+  };
+}
+
+// ---------- rollout-*.jsonl ãƒ•ã‚©ãƒ­ãƒ¯ ----------
+class JsonlFollower {
+  private timer?: NodeJS.Timeout;
+  private positions = new Map<string, number>();
+  private stopped = false;
+  constructor(
+    private sessionsDir: string,
+    private onLine: (line: string) => void,
+    private intervalMs = 200
+  ) {}
+
+  start() {
+    const tick = () => {
+      if (this.stopped) return;
+      try {
+        if (fs.existsSync(this.sessionsDir)) {
+          const stack = this.listJsonl(this.sessionsDir);
+          for (const fp of stack) this.drain(fp);
+        }
+      } catch {
+        // noop
+      }
+      this.timer = setTimeout(tick, this.intervalMs);
+    };
+    tick();
+  }
+
+  stop() {
+    this.stopped = true;
+    if (this.timer) clearTimeout(this.timer);
+  }
+
+  private listJsonl(dir: string): string[] {
+    const out: string[] = [];
+    for (const ent of safeReaddir(dir)) {
+      const p = path.join(dir, ent);
+      const st = safeStat(p);
+      if (st?.isDirectory()) out.push(...this.listJsonl(p));
+      else if (/rollout-.*\.jsonl$/.test(ent)) out.push(p);
+    }
+    return out.sort();
+  }
+
+  private drain(fp: string) {
+    const pos = this.positions.get(fp) ?? 0;
+    const st = safeStat(fp);
+    if (!st) return;
+    if (st.size < pos) {
+      // ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³/truncate
+      this.positions.set(fp, 0);
+      return;
+    }
+    if (st.size === pos) return;
+    const fd = fs.openSync(fp, "r");
+    try {
+      const len = st.size - pos;
+      const buf = Buffer.allocUnsafe(len);
+      fs.readSync(fd, buf, 0, len, pos);
+      this.positions.set(fp, st.size);
+      const text = buf.toString("utf8");
+      for (const line of text.split(/\r?\n/)) {
+        if (!line.trim()) continue;
+        this.onLine(line);
+      }
+    } finally {
+      fs.closeSync(fd);
+    }
+  }
+}
+
+function safeReaddir(dir: string): string[] {
+  try {
+    return fs.readdirSync(dir);
+  } catch {
+    return [];
+  }
+}
+function safeStat(p: string) {
+  try {
+    return fs.statSync(p);
+  } catch {
+    return undefined;
+  }
+}
+
+// ---------- ãƒ©ãƒ³ãƒŠæœ¬ä½“ ----------
+type RunAllOpts = {
+  plan: Plan;
+  assignments: Assignment[];
+  maxParallel: number;
+  codexCmd?: string;
+  codexArgs?: string[];
+  runDir: string;
+};
+
+export async function runAll(opts: RunAllOpts): Promise<number> {
+  const { plan, runDir } = opts;
+  const events = createEventsWriter(path.join(runDir, "events.ndjson"));
+  const batches = buildBatches(plan.tasks);
+  const byId = new Map<string, TaskSpec>(plan.tasks.map((t) => [t.id, t]));
+  const asnById = new Map<string, Assignment>(
+    opts.assignments.map((a) => [a.taskId, a])
+  );
+  const status = new Map<string, "pending" | "running" | "success" | "failed" | "blocked">();
+  plan.tasks.forEach((t) => status.set(t.id, "pending"));
+
+  let anyFailed = false;
+
+  for (const layer of batches) {
+    const runnable: TaskSpec[] = [];
+    for (const t of layer) {
+      const deps = t.dependsOn ?? [];
+      const failedDeps = deps.filter((d) => status.get(d) === "failed");
+      if (failedDeps.length > 0) {
+        status.set(t.id, "blocked");
+        events.write({
+          t: Date.now(),
+          type: "state",
+          runId: t.id,
+          data: { phase: "blocked", reason: "dependency_failed", deps: failedDeps },
+        });
+      } else {
+        runnable.push(t);
+      }
+    }
+
+    await runWithLimit(
+      opts.maxParallel,
+      runnable.map((t) => async () => {
+        const a = asnById.get(t.id)!;
+        fs.mkdirSync(a.codexHome, { recursive: true });
+        status.set(t.id, "running");
+        events.write({ t: Date.now(), type: "state", runId: t.id, data: { phase: "start" } });
+
+        // rollout ãƒ•ã‚©ãƒ­ãƒ¼é–‹å§‹
+        const follower = new JsonlFollower(
+          path.join(a.codexHome, "sessions"),
+          (line) => events.write({ t: Date.now(), type: "jsonl", runId: t.id, data: { line } })
+        );
+        follower.start();
+
+        const code = await spawnCodex(t.id, a, opts.codexCmd, opts.codexArgs, runDir, (kind, line) =>
+          events.write({ t: Date.now(), type: kind, runId: t.id, data: { line } })
+        );
+
+        // å°‘ã—å¾…ã£ã¦ã‹ã‚‰ follower åœæ­¢ï¼ˆæœ€å¾Œã®è¿½è¨˜ã‚’æ‹¾ã†ï¼‰
+        await new Promise((r) => setTimeout(r, 200));
+        follower.stop();
+
+        events.write({
+          t: Date.now(),
+          type: "state",
+          runId: t.id,
+          data: { phase: "exit", code },
+        });
+
+        if (code === 0) status.set(t.id, "success");
+        else {
+          status.set(t.id, "failed");
+          anyFailed = true;
+        }
+      })
+    );
+  }
+
+  await events.close();
+  return anyFailed ? 1 : 0;
+}
+
+async function runWithLimit(n: number, jobs: Array<() => Promise<void>>) {
+  const q = jobs.slice();
+  let running: Promise<void>[] = [];
+  const kick = () => {
+    while (running.length < n && q.length) running.push(q.shift()!().finally(() => {
+      running = running.filter((p) => p !== pr);
+    }));
+    const pr = Promise.race(running);
+    return pr;
+  };
+  while (running.length < n && q.length) {
+    running.push(q.shift()!().finally(() => {
+      running = running.filter((p) => p !== pr);
+    }));
+    var pr = Promise.resolve(); // eslint-disable-line
+  }
+  while (running.length || q.length) await kick();
+}
+
+function buildSpawnArgs(codexCmd?: string, codexArgs?: string[]) {
+  const cmd = codexCmd ?? "codex";
+  const args = codexArgs ?? [];
+  const isJs = cmd.endsWith(".js");
+  if (isJs) {
+    return { command: process.execPath, args: [cmd, ...args] };
+  }
+  return { command: cmd, args };
+}
+
+async function spawnCodex(
+  runId: string,
+  a: Assignment,
+  codexCmd: string | undefined,
+  codexArgs: string[] | undefined,
+  runDir: string,
+  onLine: (kind: "stdout" | "stderr", line: string) => void
+): Promise<number> {
+  const { command, args } = buildSpawnArgs(codexCmd, codexArgs);
+  const env = { ...process.env, CODEX_HOME: path.resolve(a.codexHome), SPLITSHOT_RUN_ID: runId };
+  const child = spawn(command, args, {
+    cwd: a.worktreeDir || process.cwd(),
+    env,
+    stdio: ["ignore", "pipe", "pipe"],
+    windowsHide: true,
+  });
+
+  const makeRl = (s: NodeJS.ReadableStream) =>
+    readline.createInterface({ input: s, crlfDelay: Infinity });
+
+  const outRl = makeRl(child.stdout!);
+  const errRl = makeRl(child.stderr!);
+  outRl.on("line", (l) => onLine("stdout", l));
+  errRl.on("line", (l) => onLine("stderr", l));
+
+  const code = await new Promise<number>((resolve) => {
+    child.on("close", (code) => resolve(code ?? 1));
+  });
+  return code;
+}
=== END FILE: src/core/runner.ts ===
```

```diff
=== BEGIN FILE: src/cli/run.ts ===
+import { Command } from "commander";
+import fs from "node:fs";
+import path from "node:path";
+import type { Assignments, Plan } from "../core/types";
+import { ensureUniqueCodexHomes, DuplicateCodexHomeError, runAll } from "../core/runner.js";
+
+function readJson<T>(p: string): T {
+  return JSON.parse(fs.readFileSync(path.resolve(p), "utf8")) as T;
+}
+
+export function cmdRun() {
+  const cmd = new Command("run");
+  cmd
+    .description("Execute plan tasks with scheduling and tailing Codex outputs")
+    .option("--plan <file>", "Plan JSON file")
+    .option("--assignments <file>", "Assignments JSON file")
+    .option("--max-parallel <n>", "Max parallel tasks", (v) => parseInt(v, 10), 1)
+    .option("--codex <path>", "Runner binary or JS stub", "codex-runner")
+    .option("--codex-args <args>", "Extra args (space separated)")
+    .option("--auto-isolate", "Auto suffix CODEX_HOME conflicts", false)
+    .action(async (opts) => {
+      if (!opts.plan) throw new Error("--plan is required");
+      if (!opts.assignments) throw new Error("--assignments is required");
+      const plan = readJson<Plan>(opts.plan);
+      const asn = readJson<Assignments>(opts.assignments);
+
+      let { assignments } = asn;
+      let mapping: Record<string, string> = {};
+      try {
+        const resolved = ensureUniqueCodexHomes(assignments, { autoIsolate: !!opts.autoIsolate });
+        assignments = resolved.assignments;
+        mapping = resolved.mapping;
+      } catch (e) {
+        if (e instanceof DuplicateCodexHomeError) {
+          console.error(e.message);
+          process.exit(1);
+          return;
+        }
+        throw e;
+      }
+
+      const root = path.resolve(".codex-parallel");
+      const runsBase = path.join(root, "runs");
+      fs.mkdirSync(runsBase, { recursive: true });
+      const ts = Date.now();
+      const runDir = path.join(runsBase, String(ts));
+      fs.mkdirSync(runDir, { recursive: true });
+
+      // ãƒ¡ã‚¿
+      fs.writeFileSync(
+        path.join(runDir, "run.meta.json"),
+        JSON.stringify(
+          { planId: asn.planId ?? null, codexHomes: mapping, maxParallel: opts.maxParallel },
+          null,
+          2
+        )
+      );
+
+      const codexArgs = typeof opts.codexArgs === "string" ? opts.codexArgs.split(/\s+/).filter(Boolean) : undefined;
+      const code = await runAll({
+        plan,
+        assignments,
+        maxParallel: opts.maxParallel,
+        codexCmd: opts.codex,
+        codexArgs,
+        runDir,
+      });
+
+      // latest ãƒã‚¤ãƒ³ã‚¿
+      fs.writeFileSync(path.join(runsBase, "latest.json"), JSON.stringify({ runDir }, null, 2));
+
+      process.exit(code);
+    });
+
+  return cmd;
+}
=== END FILE: src/cli/run.ts ===
```

```diff
=== BEGIN FILE: src/cli/index.ts ===
 import { Command } from "commander";
 import { version, description, name } from "../../package.json";
 import { cmdPlan } from "./plan.js";
 import { cmdAssign } from "./assign.js";   // â† è¿½åŠ 
+import { cmdRun } from "./run.js";
 
 
 const program = new Command();
 
 program
     .name(name || "splitshot")
     .description(description || "Parallel Codex planner & runner (CLI MVP)")
     .version(version);
 
 program.addCommand(cmdPlan());
 program.addCommand(cmdAssign());
+program.addCommand(cmdRun());
 
 program.parseAsync().catch((err) => {
     console.error(err instanceof Error ? err.message : String(err));
     process.exit(1);
 });
 
=== END FILE: src/cli/index.ts ===
```

```diff
=== BEGIN FILE: tests/fixtures/codex-runner-stub.js ===
+#!/usr/bin/env node
+// ãƒ©ãƒ³ãƒŠãƒ¼ç”¨ã‚¹ã‚¿ãƒ–ï¼šstdout/stderrã‚’å‡ºã—ã€CODEX_HOME/sessions ã« rollout-*.jsonl ã‚’ç”Ÿæˆ
+import fs from "node:fs";
+import path from "node:path";
+
+const runId = process.env.SPLITSHOT_RUN_ID || "unknown";
+const home = process.env.CODEX_HOME || process.cwd();
+const force = (process.env.SPLITSHOT_FORCE_FAIL_TASK_IDS || "")
+  .split(",")
+  .map((s) => s.trim())
+  .filter(Boolean);
+
+function sleep(ms) {
+  return new Promise((r) => setTimeout(r, ms));
+}
+
+async function main() {
+  process.stdout.write(`[${runId}] hello from stdout 1\n`);
+  process.stderr.write(`[${runId}] warn from stderr 1\n`);
+
+  const sess = path.join(home, "sessions", `s-${Date.now()}`);
+  fs.mkdirSync(sess, { recursive: true });
+  const f1 = path.join(sess, "rollout-1.jsonl");
+  fs.writeFileSync(f1, JSON.stringify({ runId, step: 1, msg: "start" }) + "\n");
+
+  await sleep(30);
+  fs.appendFileSync(f1, JSON.stringify({ runId, step: 2, msg: "mid" }) + "\n");
+  process.stdout.write(`[${runId}] hello from stdout 2\n`);
+
+  // æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã€Œå¾Œã‹ã‚‰ã€ç¾ã‚Œã‚‹ã‚±ãƒ¼ã‚¹
+  await sleep(30);
+  const f2 = path.join(sess, "rollout-2.jsonl");
+  fs.writeFileSync(f2, JSON.stringify({ runId, step: 3, msg: "new-file" }) + "\n");
+  process.stderr.write(`[${runId}] warn from stderr 2\n`);
+
+  if (force.includes(runId)) {
+    process.stderr.write(`[${runId}] forced failure\n`);
+    process.exit(1);
+    return;
+  }
+  process.exit(0);
+}
+
+await main();
=== END FILE: tests/fixtures/codex-runner-stub.js ===
```

```diff
=== BEGIN FILE: tests/run.e2e.test.ts ===
+import { describe, it, expect } from "vitest";
+import { spawnSync } from "node:child_process";
+import fs from "node:fs";
+import path from "node:path";
+import { tmpdir } from "node:os";
+
+const root = process.cwd();
+const cli = path.resolve("dist/cli/index.js");
+const plan = path.resolve("tests/fixtures/plan-min.json");
+const stub = path.resolve("tests/fixtures/codex-runner-stub.js");
+
+function mkTmp(prefix: string) {
+  const p = fs.mkdtempSync(path.join(tmpdir(), prefix));
+  return p;
+}
+function readLines(p: string) {
+  return fs.readFileSync(p, "utf8").trim().split(/\r?\n/).filter(Boolean);
+}
+
+describe("run (E2E): dependsOn + maxParallel=1", () => {
+  it("respects dependsOn order and emits events.ndjson", () => {
+    const work = mkTmp("splitshot-e2e-");
+    const asn = {
+      assignments: [
+        { taskId: "t1", worktreeDir: path.join(work, "wt1"), codexHome: path.join(work, ".home-t1") },
+        { taskId: "t2", worktreeDir: path.join(work, "wt2"), codexHome: path.join(work, ".home-t2") },
+      ],
+    };
+    const asnFile = path.join(work, "assignments.json");
+    fs.writeFileSync(asnFile, JSON.stringify(asn, null, 2));
+
+    const out = spawnSync(process.execPath, [
+      cli,
+      "run",
+      "--plan",
+      plan,
+      "--assignments",
+      asnFile,
+      "--codex",
+      stub,
+      "--max-parallel",
+      "1",
+    ], { cwd: root });
+
+    expect(out.status, String(out.stderr)).toBe(0);
+
+    const latest = JSON.parse(
+      fs.readFileSync(path.join(work, ".codex-parallel", "runs", "latest.json"), "utf8")
+    );
+    const ev = readLines(path.join(latest.runDir, "events.ndjson")).map((l) => JSON.parse(l));
+
+    const starts = ev.filter((e) => e.type === "state" && e.data?.phase === "start").map((e) => e.runId);
+    // t1 ãŒå…ˆã€t2 ãŒå¾Œ
+    expect(starts[0]).toBe("t1");
+    expect(starts[1]).toBe("t2");
+  });
+});
=== END FILE: tests/run.e2e.test.ts ===
```

```diff
=== BEGIN FILE: tests/run.auto-isolate.e2e.test.ts ===
+import { describe, it, expect } from "vitest";
+import { spawnSync } from "node:child_process";
+import fs from "node:fs";
+import path from "node:path";
+import { tmpdir } from "node:os";
+
+const root = process.cwd();
+const cli = path.resolve("dist/cli/index.js");
+const plan = path.resolve("tests/fixtures/plan-min.json");
+const stub = path.resolve("tests/fixtures/codex-runner-stub.js");
+
+function mkTmp(prefix: string) {
+  return fs.mkdtempSync(path.join(tmpdir(), prefix));
+}
+function readLines(p: string) {
+  return fs.readFileSync(p, "utf8").trim().split(/\r?\n/).filter(Boolean);
+}
+
+describe("run: CODEX_HOME conflicts", () => {
+  it("fails without --auto-isolate", () => {
+    const work = mkTmp("splitshot-conf-");
+    const shared = path.join(work, ".home-shared");
+    const asn = {
+      assignments: [
+        { taskId: "t1", worktreeDir: path.join(work, "wt1"), codexHome: shared },
+        { taskId: "t2", worktreeDir: path.join(work, "wt2"), codexHome: shared },
+      ],
+    };
+    const asnFile = path.join(work, "assign.json");
+    fs.writeFileSync(asnFile, JSON.stringify(asn, null, 2));
+
+    const out = spawnSync(process.execPath, [
+      cli,
+      "run",
+      "--plan",
+      plan,
+      "--assignments",
+      asnFile,
+      "--codex",
+      stub,
+      "--max-parallel",
+      "2",
+    ], { cwd: root });
+
+    expect(out.status).not.toBe(0);
+    const err = (out.stderr || Buffer.alloc(0)).toString();
+    expect(err).toMatch(/Duplicate CODEX_HOME/i);
+  });
+
+  it("succeeds with --auto-isolate and both tasks start", () => {
+    const work = mkTmp("splitshot-auto-");
+    const shared = path.join(work, ".home-shared");
+    const asn = {
+      assignments: [
+        { taskId: "t1", worktreeDir: path.join(work, "wt1"), codexHome: shared },
+        { taskId: "t2", worktreeDir: path.join(work, "wt2"), codexHome: shared },
+      ],
+    };
+    const asnFile = path.join(work, "assign.json");
+    fs.writeFileSync(asnFile, JSON.stringify(asn, null, 2));
+
+    const out = spawnSync(process.execPath, [
+      cli,
+      "run",
+      "--plan",
+      plan,
+      "--assignments",
+      asnFile,
+      "--codex",
+      stub,
+      "--max-parallel",
+      "2",
+      "--auto-isolate",
+    ], { cwd: root });
+
+    expect(out.status, String(out.stderr)).toBe(0);
+
+    const latest = JSON.parse(fs.readFileSync(path.join(work, ".codex-parallel", "runs", "latest.json"), "utf8"));
+    const lines = readLines(path.join(latest.runDir, "events.ndjson"));
+    const starts = lines.map((l) => JSON.parse(l)).filter((e) => e.type === "state" && e.data?.phase === "start").map((e) => e.runId);
+    expect(new Set(starts)).toEqual(new Set(["t1", "t2"]));
+  });
+});
=== END FILE: tests/run.auto-isolate.e2e.test.ts ===
```

```diff
=== BEGIN FILE: tests/run.propagation.e2e.test.ts ===
+import { describe, it, expect } from "vitest";
+import { spawnSync } from "node:child_process";
+import fs from "node:fs";
+import path from "node:path";
+import { tmpdir } from "node:os";
+
+const root = process.cwd();
+const cli = path.resolve("dist/cli/index.js");
+const plan = path.resolve("tests/fixtures/plan-min.json");
+const stub = path.resolve("tests/fixtures/codex-runner-stub.js");
+
+function mkTmp(prefix: string) {
+  return fs.mkdtempSync(path.join(tmpdir(), prefix));
+}
+function readLines(p: string) {
+  return fs.readFileSync(p, "utf8").trim().split(/\r?\n/).filter(Boolean);
+}
+
+describe("run: failure propagation", () => {
+  it("marks dependent tasks as blocked and exits non-zero", () => {
+    const work = mkTmp("splitshot-prop-");
+    const asn = {
+      assignments: [
+        { taskId: "t1", worktreeDir: path.join(work, "wt1"), codexHome: path.join(work, ".home-t1") },
+        { taskId: "t2", worktreeDir: path.join(work, "wt2"), codexHome: path.join(work, ".home-t2") }, // dependsOn: t1 (plan-minå´)
+      ],
+    };
+    const asnFile = path.join(work, "assign.json");
+    fs.writeFileSync(asnFile, JSON.stringify(asn, null, 2));
+
+    const out = spawnSync(process.execPath, [
+      cli,
+      "run",
+      "--plan",
+      plan,
+      "--assignments",
+      asnFile,
+      "--codex",
+      stub,
+      "--max-parallel",
+      "1",
+    ], {
+      cwd: root,
+      env: {
+        ...process.env,
+        SPLITSHOT_FORCE_FAIL_TASK_IDS: "t1",
+      },
+    });
+
+    expect(out.status).not.toBe(0);
+
+    const latest = JSON.parse(fs.readFileSync(path.join(work, ".codex-parallel", "runs", "latest.json"), "utf8"));
+    const evs = readLines(path.join(latest.runDir, "events.ndjson")).map((l) => JSON.parse(l));
+    const starts = evs.filter((e) => e.type === "state" && e.data?.phase === "start").map((e) => e.runId);
+    expect(starts).toContain("t1");
+    expect(starts).not.toContain("t2");
+
+    const blocked = evs.find((e) => e.type === "state" && e.runId === "t2" && e.data?.phase === "blocked");
+    expect(blocked?.data?.reason).toBe("dependency_failed");
+    expect(blocked?.data?.deps).toContain("t1");
+  });
+});
=== END FILE: tests/run.propagation.e2e.test.ts ===
```

---

## ã“ã“ã¾ã§ã§æº€ãŸã—ãŸTODO

* âœ… `--assignments <file>` èª­ã¿è¾¼ã¿
* âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å±¤å®Ÿè¡Œï¼ˆ`buildBatches`ï¼‰
* âœ… `--max-parallel` ã‚»ãƒãƒ•ã‚©ï¼ˆè‡ªå‰ concurrency limiterï¼‰
* âœ… ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•ï¼ˆ`spawn` / `cwd=worktreeDir` / `env.CODEX_HOME` / `.js`ã¯`process.execPath`çµŒç”±ï¼‰
* âœ… `--codex-args` é€é
* âœ… **CODEX_HOMEç«¶åˆæ¤œçŸ¥** / `--auto-isolate`
* âœ… **ãƒ­ã‚°åé›†** `stdout` / `stderr` è¡Œå˜ä½ â†’ `events.ndjson`
* âœ… **jsonlå–ã‚Šè¾¼ã¿**ï¼š`$CODEX_HOME/sessions/**/rollout-*.jsonl` ã‚’**å¾Œå‡ºã—ã«ã‚‚è¿½å¾“**
* âœ… **çŠ¶æ…‹ç®¡ç†**ï¼š`start/exit/blocked` ã‚¤ãƒ™ãƒ³ãƒˆã€exit code è¨˜éŒ²
* âœ… **å¤±æ•—ä¼æ’­**ï¼šä¾å­˜å¤±æ•— â†’ `blocked`ï¼ˆstartã—ãªã„ï¼‰
* âœ… **çµ‚äº†ã‚³ãƒ¼ãƒ‰**ï¼šã„ãšã‚Œã‹å¤±æ•—ã§é0
* âœ… **ãƒ†ã‚¹ãƒˆ**ï¼š
  * E2Eï¼ˆä¾å­˜é †ï¼‹maxParallel=1ã€`events.ndjson`ç”Ÿæˆï¼‰
  * `--auto-isolate` ã®å‹•ä½œï¼ˆæœ‰/ç„¡ï¼‰
  * å¤±æ•—ä¼æ’­ï¼ˆ`t1`å¤±æ•— â†’ `t2` blockedï¼‰
  * ãƒ©ãƒ³ãƒŠãƒ¼ã‚¹ã‚¿ãƒ–ã§ `stdout/stderr/jsonl` å‡ºåŠ›ï¼ˆå¾Œå‡ºã—jsonlå«ã‚€ï¼‰
* [ ] å¤§é‡ãƒ­ã‚°testï¼ˆæ“¬ä¼¼10ä¸‡è¡Œï¼‰ã§æ¬ è½ãªã—

> ç§è¦‹ï¼šå¤§é‡ãƒ­ã‚°ï¼ˆ10ä¸‡è¡Œï¼‰ãƒ†ã‚¹ãƒˆã¯æœ¬ä½“ãŒå®‰å®šã—ã¦ã‹ã‚‰åˆ†é›¢ãƒ†ã‚¹ãƒˆã«ã—ãŸæ–¹ãŒã‚ˆã•ãã†ã€‚å¿…è¦ã«ãªã£ãŸã‚‰ `codex-runner-stub` ã«ãƒ«ãƒ¼ãƒ—å‡ºåŠ›ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¶³ã—ã¦æ¸¬å®šã—ã€`events.ndjson` ã®è¡Œæ•°ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹REDã‚’è¶³ã—ã¾ã—ã‚‡ã†ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ã¯ç°¡æ˜“cork/uncorkã§æ—¢ã«å…¥ã‚Œã¦ã‚ã‚Šã¾ã™ã€‚




### B. `tail` ã‚³ãƒãƒ³ãƒ‰ï¼ˆãƒŸãƒ‹ãƒãƒ ï¼‰

* [ ] `events.ndjson` ã®ãƒ•ã‚©ãƒ­ãƒ¼ï¼ˆ`--run <id|all>` / `--type` ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
* [ ] è‰²ä»˜ã‘ï¼ˆä»»æ„ï¼‰
* [ ] ãƒ†ã‚¹ãƒˆï¼šãƒ•ã‚£ãƒ«ã‚¿ã¨è¿½å°¾ãŒåŠ¹ã

### C. `assign` ã®æ‹¡å¼µï¼ˆä»•æ§˜ã«ã‚ã£ãŸåˆ†ï¼‰

* [ ] **è‡ªå‹• worktree ä½œæˆ**ï¼š`--worktree-root` / `--auto-worktree` / `--branch-prefix`
* [ ] `git` å‘¼ã³å‡ºã—ãƒ˜ãƒ«ãƒ‘ï¼ˆ`git.ts`ï¼‰ï¼‹ã‚¹ã‚¿ãƒ–ãƒ†ã‚¹ãƒˆ

---

## ğŸ§ª å“è³ª/DXï¼ˆMVPåŒæ¢±ã—ãŸã„ï¼‰

* [ ] `detectCodexFeatures` ã®å˜ä½“ãƒ†ã‚¹ãƒˆï¼ˆhelpå‡ºåŠ›ã‚¹ã‚¿ãƒ–ï¼‰
* [ ] `schema.ts` ã‚¨ãƒ©ãƒ¼ç³»ãƒ†ã‚¹ãƒˆï¼ˆå¿…é ˆé …ç›®æ¬ è½ï¼‰
* [ ] `planner`/`readMaybeFile` ã®å˜ä½“ãƒ†ã‚¹ãƒˆ
* [ ] `pnpm check` ã‚’CIï¼ˆGitHub Actionsï¼‰ã«å°å…¥ï¼šLinux/Windows Ã— Node 18/20/22
* [ ] READMEï¼šQuickstartï¼ˆã‚¹ã‚¿ãƒ–/å®Ÿæ©ŸCodexã®ä¸¡æ–¹ï¼‰ã€ã‚³ãƒãƒ³ãƒ‰ä¾‹
* [ ] ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€`engines`ã€`example/`ï¼ˆ`objective.md` ãªã©ï¼‰

---

## ğŸ¯ ç›´è¿‘ã®â€œæ¬¡ã®3æ‰‹â€

1. **`run` ã®RED**ï¼šæœ€å°E2Eï¼ˆ2å±¤ï¼‹max-parallel=1ï¼‰ã§`events.ndjson`ç”Ÿæˆã‚’æœŸå¾… â†’ å¤±æ•—ã•ã›ã‚‹
2. **Runner/Tailerã®ã‚¹ã‚¿ãƒ–GREEN**ï¼šå¤–éƒ¨`codex`ã‚’ã¾ã å‘¼ã°ãšã€æ“¬ä¼¼ãƒ—ãƒ­ã‚»ã‚¹ã§`events.ndjson`ã‚’æ›¸ã‹ã›ã‚‹
3. **å®Ÿãƒ—ãƒ­ã‚»ã‚¹å·®ã—æ›¿ãˆ**ï¼š`spawn`ï¼‹CODEX_HOMEè¨­å®šâ†’`rollout-*.jsonl`å–ã‚Šè¾¼ã¿â†’å¤±æ•—ä¼æ’­

---

ä½•ã‹é †åºã‚’å¾®èª¿æ•´ã—ãŸã‘ã‚Œã°è¨€ã£ã¦ã€‚`run` ã® RED ç”¨ãƒ†ã‚¹ãƒˆé››å½¢ã‚‚ã™ãå‡ºã›ã¾ã™ï¼ˆç§è¦‹ï¼‰ã€‚
